# 一小时总结 -- 问题：服务器经常宕机，如何分析和处理。


## 先考虑本质

- why：服务器为什么宕机？
- 宕机的现象是什么：进程挂掉 or 进程存在但是拒绝服务？
- 明白了现象再去找 why；

## 进程挂掉（JVM 崩溃了）

- 现象：服务器服务一段时间后，进程就挂掉了。
- 本质：JVM Crash，发生了致命错误或主动完成退出了。
- 猜测：
	- 最大可能性：发生了 Error，要注意不是所有 Error 都一定会让 JVM 立即崩溃，但是大部分 Error 会让 JVM 退出；
	- 最低级错误：JVM 运行完成退出了，调用了 System.exit(); 
	- 特殊错误：写了 Native 方法，Navtive 方法崩溃了。
- 证明：
	- 优先：找 JVM 有没有产生 error.log，如果没有可以添加：-XX:ErrorFile=/var/log/java/java_error\_%p.log 让 JVM Crash 的时候打印异常原因；
	- 其次：看 应用及 GC 日志有没有 OOM 等 Error 日志；
	- 技巧：添加一个方法注册 JVM 的回调（jvm shutdown hook）然后在回调里面 MXBean 打印相关退出时的 GC、Thread、死锁信息；
- 解决：
	- 如果是 OOM 等 Error：使用 GC 日志、JMap、堆内存转储等方式确定 OOM 问题修复它。
	- 如果是 Native 等造成的，修复对应的 Bug；
	- 如果是自己 Exit 了，自己呵呵吧。

## 进程存在但是拒绝服务

- 现象：服务器进程存活，但是新的连接时间很长认为服务宕机了。
- 本质：本质就是新的连接（请求）排队了，JVM 处理不了这么多请求，这样就超时了。这个排队（阻塞）的地方有两个
	- 在 OS 层做 TCP 连接排队（connection timeout）；
	- 在 JVM 层 Block 等待处理（read timeout）；
	- 在 JVM 层 开始处理但是等待返回（read timeout）；
- 猜测：
	- 资源充足 JVM 的并发线程太少：如果是 Tomcat 这样的采用了 IO 多路服务用的情况，maxThread 太少，则限制了并发，比如就 10 个并发，及时每个 Thread 的 req 处理都很快，总会有一个 TPS 上限：maxThread * (1s / 每个请求平均耗时)
	- 资源充足 JVM 的并发线程合理但是响应太慢：maxThread 是合理的，网络模型是合理的，每个请求处理慢。资源充足表示不可能是硬件限制了请求处理时间，那很可能是锁或者下游服务限制了处理或者 Bug。
	- 资源不充足了 JVM 当前压力过大，所有请求都在努力处理但是奈何任务太多。
- 证明：
	- 先查看 OS 当前的连接数：netstat -an | grep -l "80" | wc -l 
	- 查看 OS 的资源情况：top，freememory、cpu us、load，pid 的 IVR 等信息；
	- 使用 jstack 查看并发线程数量和状态及是否有死锁等。
- 解决：
	- 扩容：不管是否有 bug，用机器顶能暂时恢复，如果真的是压力很大，程序没错，必须要扩容，如果是其他问题，先让服务临时恢复。
	- 优化配置：扩大最大 thread 优化内核参数，如内核默认限制 TCP 并发连接是 1024，tomcat 默认并发在 200，频繁 fullgc 导致了卡顿，配置 jvm 等。
	- 优化代码：如果是因为产生了死锁、锁等待，就用 jstack 等命令找到锁的竞争地方，去锁、降低锁粒度、换锁种类来解决。